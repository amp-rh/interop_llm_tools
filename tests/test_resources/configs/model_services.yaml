model_services:
  ollama:
    client_type: ollama
    base_api_url: $LLM_CLIENT_API_BASE
    request_timeout: 300
    instruct_model_name: $LLM_INSTRUCT_MODEL_NAME
    embed_model_name: $LLM_EMBED_MODEL_NAME
    temperature: 0

